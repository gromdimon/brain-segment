{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3600c797-8baa-4197-8b71-bde74f965c73",
   "metadata": {},
   "source": [
    "# Brain Tumor Segmentation\n",
    "- Example of brain tumor segmentation using U-Net model\n",
    "- 01.04.2024\n",
    "- by gromdimon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97239ecd",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "First of all you'll need to activate the conda environment and install all the necessary packages. \n",
    "Then you can import the libraries and modules that you'll need for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "154770c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -c \"import monai\" || pip install -q \"monai-weekly[gdown, nibabel, tqdm, ignite]\"\n",
    "# !python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5198b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap_external>:572: DeprecationWarning: find_module() is deprecated and slated for removal in Python 3.12; use find_spec() instead\n",
      "<frozen importlib._bootstrap_external>:1523: DeprecationWarning: FileFinder.find_loader() is deprecated and slated for removal in Python 3.12; use find_spec() instead\n",
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
      "/home/mahu10/.conda/envs/brain-segm/lib/python3.10/site-packages/monai/utils/module.py:403: DeprecationWarning: Please import `distance_transform_cdt` from the `scipy.ndimage` namespace; the `scipy.ndimage.morphology` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  the_module = getattr(the_module, name)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "monai.networks.nets.unet.UNet"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from monai.networks.nets import UNet\n",
    "\n",
    "\n",
    "UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20152a72-7478-4f31-aa3f-f2c64580c238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.3.0\n",
      "Numpy version: 1.26.0\n",
      "Pytorch version: 2.2.2\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 865972f7a791bf7b42efbcd87c8402bd865b329e\n",
      "MONAI __file__: /home/<username>/.conda/envs/brain-segm/lib/python3.10/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.5.0.post2\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: 0.22.0\n",
      "scipy version: 1.13.0\n",
      "Pillow version: 10.3.0\n",
      "Tensorboard version: 2.16.2\n",
      "gdown version: 4.7.3\n",
      "TorchVision version: 0.17.2\n",
      "tqdm version: 4.66.2\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: 2.2.2\n",
      "einops version: 0.7.0\n",
      "transformers version: 4.39.3\n",
      "mlflow version: 1.2.0\n",
      "pynrrd version: 1.0.0\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    Activationsd,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    MapTransform,\n",
    "    NormalizeIntensityd,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureChannelFirstd,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "import torch\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee1f7e29-36d4-41b0-b7ed-971cf8b3844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add local directories to use them as module\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")  # go to parent dir\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "285f9864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set deterministic training for reproducibility\n",
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b26b8b",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "The dataset is already prepared and can be accessed via DecathlonDataet class from MONAI library.\n",
    "Utilize the utility functions to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35cd6990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /sc-projects/sc-proj-dh-ag-eils-ml/brain_segm/brain-segment/src/data\n",
      "2024-04-26 17:31:08,020 - INFO - Verified 'Task01_BrainTumour.tar', md5: 240a19d752f0d9e9101544901065d872.\n",
      "2024-04-26 17:31:08,023 - INFO - File exists: /sc-projects/sc-proj-dh-ag-eils-ml/brain_segm/brain-segment/src/data/Task01_BrainTumour.tar, skipped downloading.\n",
      "2024-04-26 17:31:08,038 - INFO - Non-empty folder exists in /sc-projects/sc-proj-dh-ag-eils-ml/brain_segm/brain-segment/src/data/Task01_BrainTumour, skipped extracting.\n",
      "Data directory: /sc-projects/sc-proj-dh-ag-eils-ml/brain_segm/brain-segment/src/data\n",
      "2024-04-26 17:31:32,466 - INFO - Verified 'Task01_BrainTumour.tar', md5: 240a19d752f0d9e9101544901065d872.\n",
      "2024-04-26 17:31:32,468 - INFO - File exists: /sc-projects/sc-proj-dh-ag-eils-ml/brain_segm/brain-segment/src/data/Task01_BrainTumour.tar, skipped downloading.\n",
      "2024-04-26 17:31:32,473 - INFO - Non-empty folder exists in /sc-projects/sc-proj-dh-ag-eils-ml/brain_segm/brain-segment/src/data/Task01_BrainTumour, skipped extracting.\n"
     ]
    }
   ],
   "source": [
    "from src.utils import load_data, train_transform, val_transform\n",
    "\n",
    "# Training data\n",
    "train_loader, train_ds = load_data(train=True)\n",
    "# Validation data\n",
    "val_loader, val_ds = load_data(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551c881a",
   "metadata": {},
   "source": [
    "## Create Model, Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4037054-c5a2-4b79-98be-fcb1c5804ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ac3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the training parameters\n",
    "max_epochs = 30\n",
    "val_interval = 1\n",
    "VAL_AMP = True\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.device_count() else \"cpu\"\n",
    "\n",
    "# Create UNet\n",
    "# TODO: Adjust the parameters of the UNet\n",
    "model = UNet(\n",
    "    spatial_dims=3,   # 3D images\n",
    "    in_channels=4,   # Input chanels based on our images\n",
    "    out_channels=3,   # We predict 3 output classes\n",
    "    channels=(16, 32, 64),\n",
    "    strides=(2, 2),\n",
    "    num_res_units=2,\n",
    "    act='PRELU',\n",
    "    norm='INSTANCE',\n",
    "    dropout=0.1,\n",
    "    bias=True,\n",
    "    adn_ordering='NDA'\n",
    ")\n",
    "\n",
    "# Create loss function and optimizer\n",
    "loss_function = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, to_onehot_y=False, sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "\n",
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "\n",
    "# define inference method\n",
    "def inference(input):\n",
    "    def _compute(input):\n",
    "        return sliding_window_inference(\n",
    "            inputs=input,\n",
    "            roi_size=(240, 240, 160),\n",
    "            sw_batch_size=1,\n",
    "            predictor=model,\n",
    "            overlap=0.5,\n",
    "        )\n",
    "\n",
    "    if VAL_AMP:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            return _compute(input)\n",
    "    else:\n",
    "        return _compute(input)\n",
    "\n",
    "\n",
    "if device == \"cpu\":\n",
    "    pass\n",
    "else:   # if device == \"cuda:0\":\n",
    "    # use amp to accelerate training\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    # enable cuDNN benchmark\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cee774",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68157aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "best_metrics_epochs_and_time = [[], [], []]\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "metric_values_tc = []\n",
    "metric_values_wt = []\n",
    "metric_values_et = []\n",
    "\n",
    "total_start = time.time()\n",
    "for epoch in range(max_epochs):\n",
    "    epoch_start = time.time()\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step_start = time.time()\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        if device == \"cpu\":\n",
    "            # Regular precision for CPU\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:  # if device == \"cuda:0\":\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "        epoch_loss += loss.item()\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}\"\n",
    "            f\", train_loss: {loss.item():.4f}\"\n",
    "            f\", step time: {(time.time() - step_start):.4f}\"\n",
    "        )\n",
    "    lr_scheduler.step()\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                val_outputs = inference(val_inputs)\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                dice_metric_batch(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            metric_values.append(metric)\n",
    "            metric_batch = dice_metric_batch.aggregate()\n",
    "            metric_tc = metric_batch[0].item()\n",
    "            metric_values_tc.append(metric_tc)\n",
    "            metric_wt = metric_batch[1].item()\n",
    "            metric_values_wt.append(metric_wt)\n",
    "            metric_et = metric_batch[2].item()\n",
    "            metric_values_et.append(metric_et)\n",
    "            dice_metric.reset()\n",
    "            dice_metric_batch.reset()\n",
    "\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                best_metrics_epochs_and_time[0].append(best_metric)\n",
    "                best_metrics_epochs_and_time[1].append(best_metric_epoch)\n",
    "                best_metrics_epochs_and_time[2].append(time.time() - total_start)\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    os.path.join(root_dir, \"best_metric_model.pth\"),\n",
    "                )\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\" tc: {metric_tc:.4f} wt: {metric_wt:.4f} et: {metric_et:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f}\"\n",
    "                f\" at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "    print(f\"time consuming of epoch {epoch + 1} is: {(time.time() - epoch_start):.4f}\")\n",
    "total_time = time.time() - total_start\n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}, total time: {total_time}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaac0be",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d504eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and metrics\n",
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"red\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"green\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(\"train\", (18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Val Mean Dice TC\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_tc))]\n",
    "y = metric_values_tc\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"blue\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Val Mean Dice WT\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_wt))]\n",
    "y = metric_values_wt\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"brown\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Val Mean Dice ET\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_et))]\n",
    "y = metric_values_et\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"purple\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6e9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the best model output with the input image and label\n",
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # select one image to evaluate and visualize the model output\n",
    "    val_input = val_ds[6][\"image\"].unsqueeze(0).to(device)\n",
    "    roi_size = (128, 128, 64)\n",
    "    sw_batch_size = 4\n",
    "    val_output = inference(val_input)\n",
    "    val_output = post_trans(val_output[0])\n",
    "    plt.figure(\"image\", (24, 6))\n",
    "    for i in range(4):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.title(f\"image channel {i}\")\n",
    "        plt.imshow(val_ds[6][\"image\"][i, :, :, 70].detach().cpu(), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    # visualize the 3 channels label corresponding to this image\n",
    "    plt.figure(\"label\", (18, 6))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.title(f\"label channel {i}\")\n",
    "        plt.imshow(val_ds[6][\"label\"][i, :, :, 70].detach().cpu())\n",
    "    plt.show()\n",
    "    # visualize the 3 channels model output corresponding to this image\n",
    "    plt.figure(\"output\", (18, 6))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.title(f\"output channel {i}\")\n",
    "        plt.imshow(val_output[i, :, :, 70].detach().cpu())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ef2de5-072c-4af7-9abe-38272ac039a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
